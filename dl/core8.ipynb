{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Clasificación de Tumores con MLP (PyTorch)\n",
                "\n",
                "Este notebook implementa una red neuronal de perceptrón multicapa (MLP) utilizando PyTorch para predecir si un tumor es benigno o maligno."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Paso 1: Cargar y explorar los datos\n",
                "Se carga el dataset, se eliminan columnas irrelevantes y se convierten las variables categóricas a formato numérico."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 569 entries, 0 to 568\n",
                        "Data columns (total 31 columns):\n",
                        " #   Column                   Non-Null Count  Dtype  \n",
                        "---  ------                   --------------  -----  \n",
                        " 0   diagnosis                569 non-null    int64  \n",
                        " 1   radius_mean              569 non-null    float64\n",
                        " 2   texture_mean             569 non-null    float64\n",
                        " 3   perimeter_mean           569 non-null    float64\n",
                        " 4   area_mean                569 non-null    float64\n",
                        " 5   smoothness_mean          569 non-null    float64\n",
                        " 6   compactness_mean         569 non-null    float64\n",
                        " 7   concavity_mean           569 non-null    float64\n",
                        " 8   concave points_mean      569 non-null    float64\n",
                        " 9   symmetry_mean            569 non-null    float64\n",
                        " 10  fractal_dimension_mean   569 non-null    float64\n",
                        " 11  radius_se                569 non-null    float64\n",
                        " 12  texture_se               569 non-null    float64\n",
                        " 13  perimeter_se             569 non-null    float64\n",
                        " 14  area_se                  569 non-null    float64\n",
                        " 15  smoothness_se            569 non-null    float64\n",
                        " 16  compactness_se           569 non-null    float64\n",
                        " 17  concavity_se             569 non-null    float64\n",
                        " 18  concave points_se        569 non-null    float64\n",
                        " 19  symmetry_se              569 non-null    float64\n",
                        " 20  fractal_dimension_se     569 non-null    float64\n",
                        " 21  radius_worst             569 non-null    float64\n",
                        " 22  texture_worst            569 non-null    float64\n",
                        " 23  perimeter_worst          569 non-null    float64\n",
                        " 24  area_worst               569 non-null    float64\n",
                        " 25  smoothness_worst         569 non-null    float64\n",
                        " 26  compactness_worst        569 non-null    float64\n",
                        " 27  concavity_worst          569 non-null    float64\n",
                        " 28  concave points_worst     569 non-null    float64\n",
                        " 29  symmetry_worst           569 non-null    float64\n",
                        " 30  fractal_dimension_worst  569 non-null    float64\n",
                        "dtypes: float64(30), int64(1)\n",
                        "memory usage: 137.9 KB\n",
                        "None\n",
                        "        diagnosis  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
                        "count  569.000000   569.000000    569.000000      569.000000   569.000000   \n",
                        "mean     0.372583    14.127292     19.289649       91.969033   654.889104   \n",
                        "std      0.483918     3.524049      4.301036       24.298981   351.914129   \n",
                        "min      0.000000     6.981000      9.710000       43.790000   143.500000   \n",
                        "25%      0.000000    11.700000     16.170000       75.170000   420.300000   \n",
                        "50%      0.000000    13.370000     18.840000       86.240000   551.100000   \n",
                        "75%      1.000000    15.780000     21.800000      104.100000   782.700000   \n",
                        "max      1.000000    28.110000     39.280000      188.500000  2501.000000   \n",
                        "\n",
                        "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
                        "count       569.000000        569.000000      569.000000           569.000000   \n",
                        "mean          0.096360          0.104341        0.088799             0.048919   \n",
                        "std           0.014064          0.052813        0.079720             0.038803   \n",
                        "min           0.052630          0.019380        0.000000             0.000000   \n",
                        "25%           0.086370          0.064920        0.029560             0.020310   \n",
                        "50%           0.095870          0.092630        0.061540             0.033500   \n",
                        "75%           0.105300          0.130400        0.130700             0.074000   \n",
                        "max           0.163400          0.345400        0.426800             0.201200   \n",
                        "\n",
                        "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
                        "count     569.000000  ...    569.000000     569.000000       569.000000   \n",
                        "mean        0.181162  ...     16.269190      25.677223       107.261213   \n",
                        "std         0.027414  ...      4.833242       6.146258        33.602542   \n",
                        "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
                        "25%         0.161900  ...     13.010000      21.080000        84.110000   \n",
                        "50%         0.179200  ...     14.970000      25.410000        97.660000   \n",
                        "75%         0.195700  ...     18.790000      29.720000       125.400000   \n",
                        "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
                        "\n",
                        "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
                        "count   569.000000        569.000000         569.000000       569.000000   \n",
                        "mean    880.583128          0.132369           0.254265         0.272188   \n",
                        "std     569.356993          0.022832           0.157336         0.208624   \n",
                        "min     185.200000          0.071170           0.027290         0.000000   \n",
                        "25%     515.300000          0.116600           0.147200         0.114500   \n",
                        "50%     686.500000          0.131300           0.211900         0.226700   \n",
                        "75%    1084.000000          0.146000           0.339100         0.382900   \n",
                        "max    4254.000000          0.222600           1.058000         1.252000   \n",
                        "\n",
                        "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
                        "count            569.000000      569.000000               569.000000  \n",
                        "mean               0.114606        0.290076                 0.083946  \n",
                        "std                0.065732        0.061867                 0.018061  \n",
                        "min                0.000000        0.156500                 0.055040  \n",
                        "25%                0.064930        0.250400                 0.071460  \n",
                        "50%                0.099930        0.282200                 0.080040  \n",
                        "75%                0.161400        0.317900                 0.092080  \n",
                        "max                0.291000        0.663800                 0.207500  \n",
                        "\n",
                        "[8 rows x 31 columns]\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Cargar el dataset\n",
                "data = pd.read_csv(\"../data/breast-cancer-wisconsin-data.csv\")\n",
                "\n",
                "# Eliminar la columna 'id' y convertir 'diagnosis' a valores binarios\n",
                "data = data.drop(columns=['id'])\n",
                "data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
                "\n",
                "# Mostrar información general del dataset\n",
                "print(data.info())\n",
                "print(data.describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Paso 2: Preprocesamiento de los datos\n",
                "Normalizamos las características y dividimos los datos en conjuntos de entrenamiento y prueba."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Conjunto de entrenamiento: (455, 30), (455,)\n",
                        "Conjunto de prueba: (114, 30), (114,)\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "# Dividir en características y etiqueta\n",
                "X = data.drop(columns=['diagnosis'])\n",
                "y = data['diagnosis']\n",
                "\n",
                "# Normalizar las características\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "\n",
                "# Dividir en conjuntos de entrenamiento y prueba\n",
                "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# Verificar las formas de los conjuntos\n",
                "print(f\"Conjunto de entrenamiento: {X_train.shape}, {y_train.shape}\")\n",
                "print(f\"Conjunto de prueba: {X_test.shape}, {y_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Paso 3: Implementar la red MLP con PyTorch\n",
                "Diseñamos una red neuronal básica con PyTorch, utilizando una capa oculta con 32 neuronas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "MLP(\n",
                        "  (layer1): Linear(in_features=30, out_features=32, bias=True)\n",
                        "  (relu): ReLU()\n",
                        "  (output): Linear(in_features=32, out_features=1, bias=True)\n",
                        "  (sigmoid): Sigmoid()\n",
                        ")\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "\n",
                "# Modelo MLP\n",
                "class MLP(nn.Module):\n",
                "    def __init__(self, input_dim):\n",
                "        super(MLP, self).__init__()\n",
                "        self.layer1 = nn.Linear(input_dim, 32)\n",
                "        self.relu = nn.ReLU()\n",
                "        self.output = nn.Linear(32, 1)\n",
                "        self.sigmoid = nn.Sigmoid()\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.relu(self.layer1(x))\n",
                "        x = self.sigmoid(self.output(x))\n",
                "        return x\n",
                "\n",
                "# Crear el modelo\n",
                "input_dim = X_train.shape[1]\n",
                "model = MLP(input_dim)\n",
                "criterion = nn.BCELoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
                "\n",
                "# Mostrar la arquitectura del modelo\n",
                "print(model)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Paso 4: Entrenar el modelo\n",
                "Entrenamos el modelo utilizando el conjunto de entrenamiento y monitorizamos el rendimiento."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Época 1/50, Pérdida: 0.6643\n",
                        "Época 2/50, Pérdida: 0.6520\n",
                        "Época 3/50, Pérdida: 0.6401\n",
                        "Época 4/50, Pérdida: 0.6284\n",
                        "Época 5/50, Pérdida: 0.6170\n",
                        "Época 6/50, Pérdida: 0.6058\n",
                        "Época 7/50, Pérdida: 0.5950\n",
                        "Época 8/50, Pérdida: 0.5844\n",
                        "Época 9/50, Pérdida: 0.5740\n",
                        "Época 10/50, Pérdida: 0.5639\n",
                        "Época 11/50, Pérdida: 0.5541\n",
                        "Época 12/50, Pérdida: 0.5445\n",
                        "Época 13/50, Pérdida: 0.5350\n",
                        "Época 14/50, Pérdida: 0.5258\n",
                        "Época 15/50, Pérdida: 0.5168\n",
                        "Época 16/50, Pérdida: 0.5080\n",
                        "Época 17/50, Pérdida: 0.4994\n",
                        "Época 18/50, Pérdida: 0.4909\n",
                        "Época 19/50, Pérdida: 0.4826\n",
                        "Época 20/50, Pérdida: 0.4745\n",
                        "Época 21/50, Pérdida: 0.4665\n",
                        "Época 22/50, Pérdida: 0.4586\n",
                        "Época 23/50, Pérdida: 0.4510\n",
                        "Época 24/50, Pérdida: 0.4434\n",
                        "Época 25/50, Pérdida: 0.4360\n",
                        "Época 26/50, Pérdida: 0.4287\n",
                        "Época 27/50, Pérdida: 0.4216\n",
                        "Época 28/50, Pérdida: 0.4146\n",
                        "Época 29/50, Pérdida: 0.4077\n",
                        "Época 30/50, Pérdida: 0.4009\n",
                        "Época 31/50, Pérdida: 0.3943\n",
                        "Época 32/50, Pérdida: 0.3878\n",
                        "Época 33/50, Pérdida: 0.3814\n",
                        "Época 34/50, Pérdida: 0.3751\n",
                        "Época 35/50, Pérdida: 0.3690\n",
                        "Época 36/50, Pérdida: 0.3630\n",
                        "Época 37/50, Pérdida: 0.3570\n",
                        "Época 38/50, Pérdida: 0.3512\n",
                        "Época 39/50, Pérdida: 0.3455\n",
                        "Época 40/50, Pérdida: 0.3400\n",
                        "Época 41/50, Pérdida: 0.3345\n",
                        "Época 42/50, Pérdida: 0.3291\n",
                        "Época 43/50, Pérdida: 0.3238\n",
                        "Época 44/50, Pérdida: 0.3187\n",
                        "Época 45/50, Pérdida: 0.3136\n",
                        "Época 46/50, Pérdida: 0.3087\n",
                        "Época 47/50, Pérdida: 0.3038\n",
                        "Época 48/50, Pérdida: 0.2991\n",
                        "Época 49/50, Pérdida: 0.2945\n",
                        "Época 50/50, Pérdida: 0.2899\n"
                    ]
                }
            ],
            "source": [
                "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
                "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
                "\n",
                "# Entrenar el modelo\n",
                "epochs = 50\n",
                "for epoch in range(epochs):\n",
                "    model.train()\n",
                "    optimizer.zero_grad()\n",
                "    outputs = model(X_train_tensor).squeeze()\n",
                "    loss = criterion(outputs, y_train_tensor)\n",
                "    loss.backward()\n",
                "    optimizer.step()\n",
                "    print(f\"Época {epoch + 1}/{epochs}, Pérdida: {loss.item():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Paso 5: Evaluar el modelo\n",
                "Evaluamos el modelo en el conjunto de prueba utilizando métricas como precisión, recall, F1-score y matriz de confusión."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.95      0.99      0.97        71\n",
                        "           1       0.97      0.91      0.94        43\n",
                        "\n",
                        "    accuracy                           0.96       114\n",
                        "   macro avg       0.96      0.95      0.95       114\n",
                        "weighted avg       0.96      0.96      0.96       114\n",
                        "\n",
                        "Matriz de Confusión:\n",
                        "[[70  1]\n",
                        " [ 4 39]]\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "\n",
                "# Convertir conjunto de prueba a tensores\n",
                "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
                "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
                "\n",
                "# Predecir en el conjunto de prueba\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    y_pred = (model(X_test_tensor).squeeze() > 0.5).int().numpy()\n",
                "\n",
                "# Generar métricas de clasificación\n",
                "print(classification_report(y_test, y_pred))\n",
                "\n",
                "# Mostrar la matriz de confusión\n",
                "conf_matrix = confusion_matrix(y_test, y_pred)\n",
                "print(\"Matriz de Confusión:\")\n",
                "print(conf_matrix)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusión\n",
                "Analizamos el rendimiento del modelo y discutimos posibles mejoras para la red MLP."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
